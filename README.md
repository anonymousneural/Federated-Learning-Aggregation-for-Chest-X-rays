# FedHeurAgg: Federated Learning Aggregation for Chest X-rays

## ğŸ“‹ Project Overview
This repository implements a federated learning framework for medical image classification, specifically focused on pneumonia detection in chest X-rays. The project presents a novel aggregation method called **FedHeurAgg** that dynamically weights client contributions based on performance metrics, data characteristics, and gradient behavior.

![Federated Learning Process](federated-learning/results/test_accuracy_comparison.png)

## ğŸŒŸ Key Features
- **Multiple Aggregation Methods**: Implements 6 different aggregation strategies (FedAvg, FedHeurAgg, FedMedian, FedProx, FedTrimmedMean, FedNova)
- **Non-IID Experimentation**: Configurable non-IID distribution factors to simulate real-world heterogeneity
- **Adaptive Weighting**: Novel heuristic-based client importance scoring
- **Comprehensive Evaluation**: Detailed metrics and visualizations for comparative analysis
- **Memory-Efficient Design**: Optimizations for resource-constrained environments

## ğŸ”§ Installation

```bash
git clone https://github.com/anonymousneural/Federated-Learning-Aggregation-for-Chest-X-rays.git
cd Federated-Learning-Aggregation-for-Chest-X-rays
pip install -r federated-learning/requirements.txt
```

## ğŸ“Š Dataset
The project uses the Chest X-ray Pneumonia dataset, containing radiographic images categorized as normal or pneumonia. The dataset structure is:

```
chest_xray/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ pneumonia/
â”‚   â””â”€â”€ normal/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ pneumonia/
â”‚   â””â”€â”€ normal/
â””â”€â”€ test/
    â”œâ”€â”€ pneumonia/
    â””â”€â”€ normal/
```

The framework includes data preprocessing steps such as:
- Image rescaling (1/255)
- Data augmentation (rotation, shifts, zoom, flip, brightness adjustment)
- Class weighting to handle imbalance
- Non-IID data distribution simulation

## ğŸ§  Method: FedHeurAgg

The FedHeurAgg method introduces a novel approach that determines client importance weights based on:

1. **Data Representativeness**: Clients with more representative data distributions receive higher weights (40%)
2. **Performance Metrics**: Clients showing better accuracy improvement are prioritized (40%)
3. **Gradient Direction**: Clients whose updates better align with the global optimization direction receive higher weights (20%)

This multi-factor weighting strategy allows the model to adapt to heterogeneous client data while maintaining convergence toward optimal global performance.

## ğŸ—ï¸ Model Architecture
A memory-efficient CNN architecture is employed with:
- 3 convolutional blocks with batch normalization
- MaxPooling layers for spatial dimension reduction
- Dense layers with dropout for regularization
- Binary classification output

## ğŸ“ˆ Experimentation & Results
Experiments evaluate all aggregation methods across varying non-IID factors (0.0, 0.3, 0.6, 0.9). Key metrics include:
- Test accuracy
- Training and validation loss
- Performance convergence rates
- Computation time

Results demonstrate that FedHeurAgg achieves superior performance in highly heterogeneous settings (non-IID factors of 0.6 and 0.9) compared to traditional methods.

![Results Comparison](federated-learning/results/test_accuracy_bar_chart.png)
![Results Table](federated-learning/results/results_table.png)

## ğŸ“ Project Structure
```
federated-learning/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ models/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ test_accuracy_comparison.png
â”‚   â”œâ”€â”€ test_accuracy_bar_chart.png
â”‚   â””â”€â”€ results_table.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ aggregation/
â”‚   â”‚   â”œâ”€â”€ fedavg.py
â”‚   â”‚   â”œâ”€â”€ fedHeurAgg.py
â”‚   â”‚   â”œâ”€â”€ fedmedian.py
â”‚   â”‚   â”œâ”€â”€ fednova.py
â”‚   â”‚   â”œâ”€â”€ fedprox.py
â”‚   â”‚   â””â”€â”€ fedtrimmedmean.py
â”‚   â”œâ”€â”€ dataloader/
â”‚   â”‚   â””â”€â”€ data_utils.py
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ f1_score.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ cnn_model.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ memory.py
â”‚   â”‚   â”œâ”€â”€ plotting.py
â”‚   â”‚   â””â”€â”€ serialization.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ fed.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## âš™ï¸ Usage
To run the federated learning experiments:

```bash
cd federated-learning
python src/fed.py
```

Modify the configuration settings in `federated-learning/src/config.py` to adjust:
- Dataset path and image size
- Number of clients and local epochs
- Learning rate parameters
- Non-IID factors
- Method-specific hyperparameters

## ğŸ”¬ Citations
If you use this code in your research, please cite:

```bibtex
@inproceedings{fedheurAgg2025,
  title={FedHeurAgg: A Novel Heuristic Aggregation Method for Federated Learning on Medical Imaging},
  author={Anonymous},
  booktitle={Conference on Neural Information Processing Systems},
  year={2025}
}
```

## ğŸ“„ License
This project is licensed under the MIT License - see the `federated-learning/LICENSE` file for details.

## ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact
For inquiries, please open an issue in the repository.
